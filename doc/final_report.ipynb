{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#My Paper\n",
    "\n",
    "Depndincies\n",
    "```bash\n",
    "sudo apt-get install texlive-latex-extra\n",
    "sudo apt-get install texlive-bibtex-extra\n",
    "```\n",
    "\n",
    "Machine learning is used to in finger print images classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "#alt.renderers.enable('notebook')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from docopt import docopt\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_matrix = pd.read_csv(\"../results/accuracies.csv\")\n",
    "evaluation_matrix_base = pd.read_csv(\"../results_baseline//accuracies.csv\")\n",
    "\n",
    "head = pd.read_csv(\"../results/head.csv\")\n",
    "summary=pd.read_csv(\"../results/num_describe.csv\")\n",
    "\n",
    "test_accuracy = round(evaluation_matrix.iloc[0,1],2)\n",
    "test_recall=round(evaluation_matrix.iloc[2,1],2)\n",
    "precision_accuracy=round(evaluation_matrix.iloc[3,1],2)\n",
    "auc=round(evaluation_matrix.iloc[4,1],2)\n",
    "\n",
    "evaluation_matrix;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Table of Content:**\n",
    "* [Summary](#first-bullet)\n",
    "* [Introduction](#second-bullet)\n",
    "* [Methods](#third-bullet)\n",
    "* [Results](#fourth-bullet)\n",
    "* [Conclusions](#fifth-bullet)\n",
    "* [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "auc": "0.71",
     "precision_accuracy": "0.43",
     "test_accuracy": "0.74",
     "test_recall": "0.57"
    }
   },
   "source": [
    "# 1. Summary <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "\n",
    "In this project we try to find the best features that best predict default customers using machine learning tools. `Logestic Regression` was found to achieve acceptable results on the test data provided to the trained model. The accuracy of the model on test data was about {{test_accuracy}} and the recall on test data found to be {{test_recall}}. The precision for the model on the test was about {{precision_accuracy}} .The area under the ROC Curve for the final model is {{auc}}.\n",
    "\n",
    "Due to the risk associated with wrongly labeled customers as non-defaul the model was designed to reduce the false positive (false postive rate). This was also balanced with the overall accuracy on the training data. The model predict the following {{}} features to be the most important features to predict customers default.\n",
    "\n",
    "1. Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "2. EDUCATION\n",
    "3. MARRIAGE\n",
    "4. AGE\n",
    "5. Past monthly repayment status in September 2005\n",
    "6. Past monthly repayment status in September 2005\n",
    "7. Amount of previous payment (NT dollar) in September 2005\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "Prediction of customers defaul behavior is critically important in Risk Management. In pariticular, anticipating features associated with the highest prediction power may reduce the overall lender's credit risk. In this study we perform data analysis to learn features that predict default payment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methods <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "## Data\n",
    "We used data from the Taiwanese market in 2005. The Data Set is available from [UCI Machine Learning Repository Irvine, CA: University of California, School of Information and Computer Science](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). It is a collection of information\n",
    "containing 23 features from 30,000 customers. The data was originally publicized by Chung Hua University of Taiwan and Tamkang University of Taiwan. Features include :\n",
    "\n",
    "- `LIMIT_BAL`: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "- `SEX`: Gender(1 = male; 2 = female).\n",
    "- `EDUCATION`: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- `MARRIAGE`: Marital status (1 = married; 2 = single; 3 = others).  \n",
    "- `AGE`: Age (year).  \n",
    "- `PAY_1`, `PAY_2`, ..., `PAY_6`: Past monthly repayment status in September 2005, August 2005, ..., April 2005 respectively. ( -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.)  \n",
    "- `BILL_AMT1`, `BILL_AMT2`, ..., `BILL_AMT6`: Amount of bill statement (NT dollar) in September 2005, August 2005, ..., April 2005 respectively.  \n",
    "- `PAY_AMT1`, `PAY_AMT2`, ..., `PAY_AMT6`: Amount of previous payment (NT dollar) in September 2005, August 2005, ..., April 2005 respectively.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately after importing the data it was split into traning and test data. Only 75% of the data was used to train the models and the test data was only used to obtain the test performance of the model on unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "head": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>DEFAULT_NEXT_MONTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>27989</td>\n      <td>210000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>45810</td>\n      <td>42093</td>\n      <td>36587</td>\n      <td>3000</td>\n      <td>3018</td>\n      <td>2000</td>\n      <td>1500</td>\n      <td>1500</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2701</td>\n      <td>10000</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3615</td>\n      <td>4402</td>\n      <td>5173</td>\n      <td>2000</td>\n      <td>1500</td>\n      <td>400</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>500</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18399</td>\n      <td>210000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>21032</td>\n      <td>19497</td>\n      <td>3510</td>\n      <td>5000</td>\n      <td>5000</td>\n      <td>5000</td>\n      <td>8000</td>\n      <td>2000</td>\n      <td>4209</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14563</td>\n      <td>240000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>39</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>48905</td>\n      <td>47993</td>\n      <td>52015</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4000</td>\n      <td>0</td>\n      <td>5000</td>\n      <td>2000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11998</td>\n      <td>90000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>20172</td>\n      <td>73512</td>\n      <td>72588</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>20172</td>\n      <td>73512</td>\n      <td>3000</td>\n      <td>4000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
    }
   },
   "source": [
    "{{head}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1. Head of the data used in this study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created list for numeric and categorical features, below is the summary of the traning data. It shows that that mean, standard deviation, min, max etc. The bill amount, payment amount and credit limit ranges are roughly similar which are around 800,000. It's interesting that The medians for the bill statement amounts are around 20,000, but the medians for payment amounts are 2,000. Age ranges from 21 to 75 which is reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "summary": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>LIMIT_BAL</th>\n      <th>AGE</th>\n      <th>BILL_AMT1</th>\n      <th>BILL_AMT2</th>\n      <th>BILL_AMT3</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>count</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.00000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>2.250000e+04</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n      <td>22500.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean</td>\n      <td>167229.763556</td>\n      <td>35.487022</td>\n      <td>50992.89800</td>\n      <td>48905.718978</td>\n      <td>46629.685644</td>\n      <td>42932.418844</td>\n      <td>39905.282444</td>\n      <td>38385.688222</td>\n      <td>5714.377733</td>\n      <td>5.848260e+03</td>\n      <td>5132.902667</td>\n      <td>4728.448311</td>\n      <td>4725.760978</td>\n      <td>5282.126533</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>std</td>\n      <td>129384.485693</td>\n      <td>9.182223</td>\n      <td>73064.68632</td>\n      <td>70748.066294</td>\n      <td>68376.985307</td>\n      <td>63802.950987</td>\n      <td>60135.853082</td>\n      <td>58733.428102</td>\n      <td>17078.235838</td>\n      <td>2.191690e+04</td>\n      <td>16892.473653</td>\n      <td>15430.720628</td>\n      <td>15138.455175</td>\n      <td>18506.384982</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>min</td>\n      <td>10000.000000</td>\n      <td>21.000000</td>\n      <td>-165580.00000</td>\n      <td>-69777.000000</td>\n      <td>-157264.000000</td>\n      <td>-170000.000000</td>\n      <td>-81334.000000</td>\n      <td>-339603.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25%</td>\n      <td>50000.000000</td>\n      <td>28.000000</td>\n      <td>3565.75000</td>\n      <td>2928.000000</td>\n      <td>2577.000000</td>\n      <td>2313.000000</td>\n      <td>1711.750000</td>\n      <td>1190.000000</td>\n      <td>990.000000</td>\n      <td>8.000000e+02</td>\n      <td>390.000000</td>\n      <td>285.750000</td>\n      <td>238.000000</td>\n      <td>119.750000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50%</td>\n      <td>140000.000000</td>\n      <td>34.000000</td>\n      <td>22169.00000</td>\n      <td>20859.000000</td>\n      <td>19889.000000</td>\n      <td>18855.500000</td>\n      <td>17875.000000</td>\n      <td>16715.000000</td>\n      <td>2100.000000</td>\n      <td>2.001000e+03</td>\n      <td>1800.000000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>75%</td>\n      <td>240000.000000</td>\n      <td>41.000000</td>\n      <td>66732.75000</td>\n      <td>63104.250000</td>\n      <td>59532.500000</td>\n      <td>53339.500000</td>\n      <td>49743.000000</td>\n      <td>48863.500000</td>\n      <td>5006.000000</td>\n      <td>5.000000e+03</td>\n      <td>4512.000000</td>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max</td>\n      <td>800000.000000</td>\n      <td>75.000000</td>\n      <td>746814.00000</td>\n      <td>743970.000000</td>\n      <td>855086.000000</td>\n      <td>616836.000000</td>\n      <td>587067.000000</td>\n      <td>568638.000000</td>\n      <td>873552.000000</td>\n      <td>1.227082e+06</td>\n      <td>889043.000000</td>\n      <td>621000.000000</td>\n      <td>426529.000000</td>\n      <td>528666.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "{{summary}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2. Summary the data used in this study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn the association between numeric features we explored their inter-correlations which can be seen below. \n",
    "We can observe that some features a stronger co-linearity such as BILL-AMT1,BILL-AMT2,.. to BILL-AMT6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../results/num_corr_chart.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3. Inter-correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also study the correlation between the features and the response varibale. We can see that some of the features have stronger correlation with the response varibale than others, for example LIMIT_BALANCE and Age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../results/num_res_chart.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](roc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4. Correlation between numeric features and response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results <a class=\"anchor\" id=\"fourth-bullet\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected `LogisticRegression` as our model since it is more robus given that the dataset has many of the features are not normally distributed. In addition to that fact that is mucher interpetable than more complex models\n",
    "\n",
    "We started the analysis by applying a robust scalar on the traning data-set as most of features are not normally distributed and due to the high amount of outliers. Since the EDA analysis revealed that many features have strong multio-colinearity we used recursive feature elimination `RFE` to identify the most useful predictors. Then we dropped those columns that are deemed as less useful.\n",
    "\n",
    "The hyper parameters `C` was tunned in the range from -4 to 20 using 5-fold cross validation and the model was then fitted with the best hyper paramter. Let us now look at the result by glancing into the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../results/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5. Confusion matrix of the fitted model with 7 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best model which uses 7 features tends to correctly predict the customer that defualt better than the base case model which use all the features. This is critically importnt in risk management. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../results_baseline/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6. Confusion matrix of the fitted model with all 23 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "auc": "0.71",
     "evaluation_matrix": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test accuracy</td>\n      <td>0.740933</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train accuracy</td>\n      <td>0.741733</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test recall</td>\n      <td>0.567372</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test precision</td>\n      <td>0.433518</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>auc score</td>\n      <td>0.707454</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "precision_accuracy": "0.43",
     "test_accuracy": "0.74",
     "test_recall": "0.57"
    }
   },
   "source": [
    "In terms of accuracy the results are shown below, we can see that the accuracy of the model on test data was about {{test_accuracy}} and the recall on test data found to be {{test_recall}}. The precision for the model on the test was about {{precision_accuracy}} .The area under the ROC Curve for the final model is {{auc}}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test accuracy</td>\n",
       "      <td>0.740933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train accuracy</td>\n",
       "      <td>0.741733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test recall</td>\n",
       "      <td>0.567372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test precision</td>\n",
       "      <td>0.433518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auc score</td>\n",
       "      <td>0.707454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    result\n",
       "0   test accuracy  0.740933\n",
       "1  train accuracy  0.741733\n",
       "2     test recall  0.567372\n",
       "3  test precision  0.433518\n",
       "4       auc score  0.707454"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a good improvement over the base model which use all the 23 features as can see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test accuracy</td>\n",
       "      <td>0.676267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train accuracy</td>\n",
       "      <td>0.677244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test recall</td>\n",
       "      <td>0.656798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test precision</td>\n",
       "      <td>0.368850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auc score</td>\n",
       "      <td>0.721871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    result\n",
       "0   test accuracy  0.676267\n",
       "1  train accuracy  0.677244\n",
       "2     test recall  0.656798\n",
       "3  test precision  0.368850\n",
       "4       auc score  0.721871"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC was plotted to to measure the model's discriminative ability. We can see that the model perform fairly good compared with the base model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../results/roc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 7. ROC curve for the fitted model with 7 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusions <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "\n",
    "We were able to successfully use `LogisticRegression` model to find the most important features that predict customer default. The model acheives an acceptable level of accuracy on the testing data, better tunning of hyper paramters may result a higher accuracy. Following are the top 7 features :\n",
    "\n",
    "1. Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "2. EDUCATION\n",
    "3. MARRIAGE\n",
    "4. AGE\n",
    "5. Past monthly repayment status in September 2005\n",
    "6. Past monthly repayment status in September 2005\n",
    "7. Amount of previous payment (NT dollar) in September 2005\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Dheeru Dua and Casey Graff. UCI machine learning repository, 2017.\n",
    "\n",
    "[2] Guido Van Rossum and Fred L. Drake. Python 3 Reference Manual. CreateSpace, Scotts Valley, CA, 2009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<cite data-cite=\"Python\"></cite>\n",
    "<cite data-cite=\"Dua:2019\"></cite>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
